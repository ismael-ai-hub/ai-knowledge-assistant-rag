# AI Knowledge Assistant with RAG (Local & Free)

This project implements a Retrieval-Augmented Generation (RAG) system that allows users to query their own documents
(PDFs or text files) and receive grounded, context-aware answers.

The system is designed to be **100% local**, **cost-free**, and **enterprise-oriented**, using open-source tools
commonly adopted in modern AI agent architectures.

---

##  Key Features

- Local Large Language Model (LLM) inference using **Ollama**
- Retrieval-Augmented Generation (RAG) for factual and grounded answers
- Vector-based semantic search with **ChromaDB**
- Open-source embeddings from **Hugging Face**
- PDF document ingestion and indexing
- No external APIs or paid services required

---

##  Technology Stack

| Component | Tool |
|--------|------|
| LLM | Ollama (Mistral / LLaMA) |
| Embeddings | sentence-transformers (Hugging Face) |
| Vector Database | ChromaDB |
| RAG Framework | LangChain |
| Document Loader | PyPDF |
| Language | Python |

---

##  Project Structure

